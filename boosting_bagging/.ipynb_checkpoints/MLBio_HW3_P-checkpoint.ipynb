{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "efrE1Lc0Otrq"
   },
   "source": [
    "# **Machine Learning in Bioinformatics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GtzvENmYOtxi"
   },
   "source": [
    "**Homework 3:**<br/>\n",
    "!!! If you don't fill these fields, your homework does not count !!!<br/>\n",
    "first name and last name : Yasamin Tabatabaee<br/>\n",
    "student number : 95104866"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KG3vb72VOt4G"
   },
   "source": [
    "You can run cells by hitting `Shift` + `Enter` or `ctrl` + `Enter`.<br/>\n",
    "We highly recommend you to read each line of code carefully and try to \n",
    "understand what it exactly does.<br/>\n",
    "Just alter the parts that is between green comments and specified for you. <br/>\n",
    "Please do not change other parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v0dotHjRO5x_"
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_5C6lgUtO-bg"
   },
   "source": [
    "\n",
    "### about the Data:<br/>\n",
    "The purpose of this project is to classify tumors into malignant or benign. The following dataset is constructed based on images of tumors. Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.\n",
    "For more details about the features of this dataset you can visit this link:\n",
    "https://scikit-learn.org/stable/datasets/index.html#breast-cancer-dataset<br/>\n",
    "This dataset contains 30 features and 1 label called target.\n",
    "The original dataset labels are 0 and 1 and in the following code boxes we change it to -1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-7_g8ApcO7tm"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890     0.0  \n",
       "1          0.2750                  0.08902     0.0  \n",
       "2          0.3613                  0.08758     0.0  \n",
       "3          0.6638                  0.17300     0.0  \n",
       "4          0.2364                  0.07678     0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = load_breast_cancer()  ## change if the data set changed\n",
    "df = pd.DataFrame(np.c_[cancer[\"data\"], cancer[\"target\"]], columns = np.append(cancer[\"feature_names\"],[\"target\"]))\n",
    "features = ['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'symmetry error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jmmK95OVPDyg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.94727592267135 %\n",
      "69.94727592267135 %\n",
      "20.035149384885763 %\n",
      "20.035149384885763 %\n",
      "10.017574692442881 %\n",
      "10.017574692442881 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "cancer.target = np.where(cancer.target==0, -1, cancer.target)\n",
    "X_train ,X_test ,X_val ,y_train ,y_test ,y_val = None ,None ,None ,None ,None ,None\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# 1- Normalize tha data.                                                       #\n",
    "# 2- using train_test_split package, split your data into 3 numpy array        #\n",
    "# called X_train, X_test, and X_val and also split the corresponding labels as #\n",
    "# y_train, y_test, and y_val. After spliting, the ratio of your data should be # \n",
    "# approximately like this:                                                     #\n",
    "#  Train : 70%     test : 20%       validation : 10%                           #\n",
    "################################################################################\n",
    "\n",
    "cancer.data = preprocessing.normalize(cancer.data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size = 0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.125)\n",
    "\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "print((X_train.shape[0]/cancer.data.shape[0]) * 100, \"%\")\n",
    "print((y_train.shape[0]/cancer.data.shape[0]) * 100, \"%\")\n",
    "print((X_test.shape[0]/cancer.data.shape[0]) * 100, \"%\")\n",
    "print((y_test.shape[0]/cancer.data.shape[0]) * 100, \"%\")\n",
    "print((X_val.shape[0]/cancer.data.shape[0]) * 100, \"%\")\n",
    "print((y_val.shape[0]/cancer.data.shape[0]) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EZ3-Fm4uPIdf"
   },
   "source": [
    "# Ensemble Methods\n",
    "\n",
    "## Problem 1. Bagging (15 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZzSuFIANPPRh"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation accuracy is  91.22807017543859  for  33  number of classifiers.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection \n",
    "from sklearn.ensemble import BaggingClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn\n",
    "\n",
    "################################################################################\n",
    "# TODO : initialize the base classifier. You can choose one of the classifiers #\n",
    "# you have learned in this course.(SVM/Decision tree)                          #\n",
    "# IMPORTANT: if you are using SVM as base classifier don't forget to add column#\n",
    "# of '1' s for bias and be careful to use the right datset in next parts.      #\n",
    "################################################################################\n",
    "\n",
    "base_cls = DecisionTreeClassifier()\n",
    "  \n",
    "##################################################################################\n",
    "# TODO: Number of classifiers is a hyperparameter. Choose it by using validation #\n",
    "# data to have the best accuracy                                                 #\n",
    "# For different number of classifiers, train the model with training data and    #\n",
    "# compute accuracy for validation data. Plot accuracy-number of classifiers plot.#\n",
    "##################################################################################\n",
    "seed = 123456\n",
    "max_cls = 100\n",
    "\n",
    "cls_scores = np.zeros(max_cls)\n",
    "best_model = None\n",
    "best_score = 0.0\n",
    "best_num = 0\n",
    "\n",
    "for num_cls in range(1, max_cls + 1):\n",
    "    model = BaggingClassifier(base_estimator = base_cls, \n",
    "                          n_estimators = num_cls, \n",
    "                          random_state = seed)\n",
    "    model.fit(X_train,y_train)\n",
    "    cls_scores[num_cls - 1] = model.score(X_val, y_val)\n",
    "    if cls_scores[num_cls - 1] > best_score:\n",
    "        best_num = num_cls\n",
    "        best_model = model\n",
    "        best_score = cls_scores[num_cls - 1]\n",
    "    \n",
    "plot_accuracy_num(range(1, max_cls + 1), cls_scores) \n",
    "print(\"Best validation accuracy is \", best_score * 100, \" for \", best_num, \" number of classifiers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test data =  94.73684210526315\n",
      "Confusion Matrix = \n",
      " [[43  2]\n",
      " [ 4 65]]\n",
      "Classification Report = \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.96      0.93        45\n",
      "           1       0.97      0.94      0.96        69\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.94      0.95      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "Avg Precision =  0.9483378181878959\n",
      "Avg Recall =  0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# compute and report the accuracy for test data.                               #\n",
    "################################################################################\n",
    "y_preds = best_model.predict(X_test)\n",
    "print(\"Accuracy for test data = \", accuracy_score(y_test, y_preds) * 100)                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_num(cls_nums, cls_scores):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(cls_nums, cls_scores)\n",
    "    plt.xlabel(\"Number of Classifiers\")\n",
    "    plt.ylabel(\"Validation Accuracy\")\n",
    "    plt.title(\"Accuracy - Num of Classifiers\")\n",
    "    plt.show()       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ELyA0acXgK2w"
   },
   "source": [
    "## Problem 2. Random Forest(25 points)</br>\n",
    "In this part, you should write your own code to classify the data, using random forest from sklearn package in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JE4eKUybgQUb"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#################################################################################\n",
    "# TODO:use the validation data to determine hyperparameters(number and depth of #\n",
    "# trees) for the best accuracy                                                  # \n",
    "#################################################################################\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 1, stop = 1000, num = 5)]\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 5)]\n",
    "params = {'n_estimators': n_estimators, 'max_depth': max_depth}\n",
    "\n",
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "rf_random = GridSearchCV(estimator = random_forest, param_grid = params, cv = 5)\n",
    "rf_random.fit(X_train, y_train)\n",
    "print(model.score(X_val, y_val))\n",
    "\n",
    "#max_trees = 10\n",
    "#max_depth = 10\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "#TODO:report accuracy, presition,recall and confusion matrix for train and test data  #\n",
    "#######################################################################################\n",
    "\n",
    "y_preds = best_model.predict(X_test)\n",
    "print(\"Accuracy for test data = \", accuracy_score(y_test, y_preds) * 100)\n",
    "print(\"Confusion Matrix = \\n\", confusion_matrix(y_test, y_preds))\n",
    "print(\"Classification Report = \\n\", classification_report(y_test, y_preds))\n",
    "print(\"Avg Precision = \", classification_report(y_test, y_preds, output_dict=True)['weighted avg']['precision'])\n",
    "print(\"Avg Recall = \", classification_report(y_test, y_preds, output_dict=True)['weighted avg']['recall']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pSr7G0fdgmyf"
   },
   "source": [
    "### Question:\n",
    "Explain how you did choose the hyperparameters.</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "etxNZ36Ugnp7"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fxpbM42MPg6m"
   },
   "source": [
    "## Problem 3. Boosting : AdaBoost (35 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rUodQdBvPrKQ"
   },
   "source": [
    "In this part you should implement adaptive boosting algorithm. </br>\n",
    "<picture>\n",
    "  <img src=\"http://uupload.ir/files/b919_adaboost.png\" alt=\"Adaboost\" width=\"600\" height=\"300\">\n",
    "</picture>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r9TL5FGqRIoL"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "X_train ,X_test ,y_train ,y_test = None ,None ,None ,None\n",
    "###################################################################\n",
    "# TODO: use 80% of normalized data as train and 20% as test data. #\n",
    "###################################################################\n",
    "\n",
    "\n",
    "######################################################################\n",
    "#TODO : define a weak decision tree.                                 #\n",
    "# initialize these parameters: criterion=\"entropy\" and max_depth = 1 #\n",
    "######################################################################\n",
    "Tree_model = DecisionTreeClassifier()\n",
    "#############################################################################################\n",
    "#TODO : report accuracy of your weak model on train and test data by using cross validation #\n",
    "#############################################################################################\n",
    "train_accuracy = np.mean(cross_validate()['test_score']) \n",
    "print('The training data accuracy is:' ,accuracy * 100 , '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "elsmjgbNRSdH"
   },
   "outputs": [],
   "source": [
    "class AdaBoost:\n",
    "    \n",
    "    def __init__(self,train_data_X,train_data_y,tree_num,test_data_X,test_data_y):\n",
    "        self.train_data_X = train_data_X\n",
    "        self.train_data_y = train_data_y\n",
    "        self.tree_num = tree_num\n",
    "        self.test_data_X = test_data_X\n",
    "        self.test_data_y = test_data_y\n",
    "        self.alphas = None\n",
    "        self.models = None\n",
    "        self.accuracy = []\n",
    "        self.predictions = None\n",
    "        \n",
    "    def fit(self):\n",
    "        Evaluation = pd.DataFrame(self.train_data_y.copy())\n",
    "        Evaluation.columns = ['target']\n",
    "        ## TODO:Set the initial weights w = 1/N\n",
    "        Evaluation['weights'] = None \n",
    "        \n",
    "        alphas = [] #list of alphas \n",
    "        models = [] # list of trained models\n",
    "        for t in range(self.tree_num):\n",
    "\n",
    "            ## TODO: create a weak decisiontree classifier\n",
    "            Tree_model = None\n",
    "            ## TODO: fit the model with train data. set the sample_weight parameter to the 'weights' columns in Evaluation dataframe\n",
    "            model = None \n",
    "            \n",
    "            models.append(model)\n",
    "            predictions = model.predict(self.train_data_X)\n",
    "            score = model.score(self.train_data_X,self.train_data_y)\n",
    "\n",
    "            ## Add this columns to the Evaluation DataFrame\n",
    "            Evaluation['predictions'] = predictions\n",
    "            ## TODO: In each row if the prediction and the target are equal,this column must be '1' and '0' O.W. \n",
    "            Evaluation['evaluation'] = None\n",
    "            ## TODO: In each row if the tha data is missclassified, this column must be 1.\n",
    "            Evaluation['misclassified'] = None\n",
    "\n",
    "            ## TODO: Calculate the misclassification rate and accuracy and then use them to calculate error\n",
    "            accuracy = None\n",
    "            misclassification = None\n",
    "            err = None\n",
    "\n",
    "            ## TODO: Calculate the alpha values from the adaboost algorithm\n",
    "            alpha = None\n",
    "            alphas.append(alpha)\n",
    "            ## TODO: update the weights\n",
    "            Evaluation['weights'] = None\n",
    "\n",
    "        self.alphas = alphas\n",
    "        self.models = models\n",
    "        \n",
    "        \n",
    "    def predict(self):\n",
    "        \n",
    "        accuracy = []\n",
    "        predictions = []\n",
    "        #####################################################################################\n",
    "        #TODO:                                                                              #\n",
    "        # 1- predict target for test data and append each prediction to the predictions list#\n",
    "        # 2- Create a list of accuracies which can be used to plot the accuracy against the #\n",
    "        # number of base learners used for the model                                        #\n",
    "        #####################################################################################\n",
    "        for alpha,model in zip(self.alphas,self.models):\n",
    "            prediction = None\n",
    "            predictions.append(prediction)\n",
    "            self.accuracy.append()\n",
    "\n",
    "            \n",
    "        self.predictions = np.sign(np.sum(np.array(predictions),axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-by9WfOXRVQG"
   },
   "outputs": [],
   "source": [
    "# Accuracy - number of base learners plot for training data\n",
    "\n",
    "number_of_base_learners = 100\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax0 = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "for i in ranage(number_of_base_learners):\n",
    "    model = AdaBoost(X_train,y_train,number_of_base_learners,X_train,y_train)\n",
    "    model.fit()\n",
    "    model.predict()\n",
    "\n",
    "ax0.plot(range(len(model.accuracy)),model.accuracy,'-b')\n",
    "ax0.set_xlabel('# models used for Boosting ')\n",
    "ax0.set_ylabel('accuracy')\n",
    "print('With a number of ',number_of_base_learners,'base models we receive an accuracy of ',model.accuracy[-1]*100,'%')    \n",
    "                 \n",
    "plt.show()   \n",
    "#################################################################### \n",
    "# TODO: Plot Accuracy - number of base learners plot for test data #\n",
    "####################################################################  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2olecphWRi4L"
   },
   "source": [
    "# Feature Selction </br>\n",
    "\n",
    "## problem4. Filtering : correlation coefficient (25 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oe0ynxveRmXS"
   },
   "outputs": [],
   "source": [
    "################################################################################# \n",
    "# TODO:                                                                         #\n",
    "# use 80% of normalized data as train and 20% as test data.(just use the data   # \n",
    "# from last part)                                                               #\n",
    "# 1- compute the correlation coefficient between each feature and target.       #\n",
    "# 2- Report the features that their correlation is more than 0.5                #\n",
    "# 3- compute the correlation between the features you reported in 2nd           #\n",
    "# section and report features that their correlation with other features        #\n",
    "# is less than 0.5                                                              #\n",
    "# 4- use perceptron from sklearn package to classify the data. Report accurracy #\n",
    "# for test data and sort the features based on their weights in perceptron.     #\n",
    "# IMPORTANT: Don't forget to add 1s to the end of feature vectors to be         #\n",
    "# multiplied by bias term of weight in perceptron.                              #\n",
    "# 5- compare the features you reported in section 2 and 3 with the features     #\n",
    "# that have the most weights in perceptron and write your analysis below        #\n",
    "# 6 - Classify data with perceptron and use only the features you repoted in    # \n",
    "# section 2 and report accuracy for test data.                                  #\n",
    "# 7 - Do the same with section 3 and compare accuracies.                        #\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o0QJrI36-GNR"
   },
   "source": [
    "explanation of part 5 and 6:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iTC2KZ1h-QO6"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k_XG0iKSRqnE"
   },
   "source": [
    "Question: Is it important to extract features before classifying using methods like decision tree and SVM? why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ro6v3JSBRsd5"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eQjRm5a6j8KZ"
   },
   "source": [
    "## problem 5. mRMR (10 bonus points) </br>\n",
    "In this part you should write your own code and classify the data using mRMR method.You can use \"pymrmr\" package for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQs-LPupRoDx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MLBio_HW3_P.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
