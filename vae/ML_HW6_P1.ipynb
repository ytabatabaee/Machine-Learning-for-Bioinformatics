{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cqukfL0Ty1fy"
   },
   "source": [
    "# ML for Bioinformatics\n",
    "## HW6 - Variational Autoencoder\n",
    "\n",
    "---\n",
    "\n",
    "Name: \n",
    "\n",
    "Student No.:\n",
    "\n",
    "---\n",
    "do not forget to insert your Name and Student No. in this cell !!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qh-SRMr9CSOD"
   },
   "source": [
    "#import library and setting device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GO3DqUsn2DN9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.auto import tqdm, trange\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0wJU1-gxBPfg"
   },
   "outputs": [],
   "source": [
    "device = None\n",
    "######################## P0 ########################## \n",
    "# check if gpu is available then put device to cuda0 #\n",
    "# else device is equal to cpu                        #\n",
    "######################################################\n",
    "\n",
    "######################## end #########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CniUSz82CcsL"
   },
   "source": [
    "#loading Data\n",
    "The MNIST database of handwritten digits contain diffrents images of digits. \n",
    "\n",
    "similar to MNIST,fashionMNIST is dataset containg 10 type of clothes instead of 10 type of digits. \n",
    "\n",
    "for example label 0 in MNIST is for 0 digit and 0 in FashionMNIST is for T-shirt. all the images is gray-scale and 28*28.\n",
    "\n",
    "for more information you can visit this [link](https://github.com/zalandoresearch/fashion-mnist) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "73OG4ZxTDJAJ"
   },
   "outputs": [],
   "source": [
    "# Get MNIST dataloader\n",
    "BATCH_SIZE = 128\n",
    "data_loader_kwargs = {\n",
    "    'batch_size': BATCH_SIZE, \n",
    "    'shuffle': True,\n",
    "    'pin_memory': True,\n",
    "    'num_workers': 4,\n",
    "}\n",
    "train_dataset = None\n",
    "test_dataset = None\n",
    "train_loader = None\n",
    "test_loader = None\n",
    "############################## P1 ##############################\n",
    "# in this cell first download the fashionMNIST dataset         #\n",
    "# for train (use toTensor transform and download = True)       #\n",
    "# and put it in train_dataset. then get test dataset          #\n",
    "# and put it in test_dataset(no need to download again).       #\n",
    "# then make train and test loader using the data_loader_kwargs #\n",
    "################################################################\n",
    "\n",
    "######################## end #########################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cJ9f4iwPEcJr"
   },
   "source": [
    "#Auto-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ArX51PbYyieD"
   },
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, input_dim, encoder_dims, z_dim, decoder_dims):\n",
    "        super(AE, self).__init__()\n",
    "        # input_dim = is the dimension of your input\n",
    "        # encoder_dims = is list containing of some integer that shows the dimension of encoder layers, between input layer and latent layer  \n",
    "        # z_dim = dimension of latent layer\n",
    "        # decoder_dims = is list containing of some integer that shows the dimension of decoder layers, between latent layer and output layer (same as input_dim)  \n",
    "        self.type_str = 'AE'\n",
    "        self.z_dim = z_dim\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        encoder_layers = list()\n",
    "        ####################### P2 ###############################\n",
    "        # Iterate over `encoder_dims` and create fully connected #\n",
    "        # layers using nn.Linear. Use ReLU activation function   #   \n",
    "        # after each FC layer using nn.ReLU Append all layers to #\n",
    "        #`encoder_layers`.                                       #\n",
    "        ##########################################################\n",
    "\n",
    "        ####################### End ########################\n",
    "        self.encoder = nn.Sequential(*encoder_layers)\n",
    "        \n",
    "        # Compute Z\n",
    "        self.z_layer = None\n",
    "        ########################  P3 #############################\n",
    "        # Define a fully connected layer that maps the output of #\n",
    "        # previous part to `z_dim` dimensions, store it in       #\n",
    "        # `self.z_layer`. No activation function is needed after #\n",
    "        # this layer.                                            #\n",
    "        ##########################################################\n",
    "        ######################## End #############################\n",
    "\n",
    "        # Decoder part\n",
    "        decoder_layers = list()\n",
    "        ########################## P4 ###############################\n",
    "        # Define the decoder part (Use `decoder_dims`)              #\n",
    "        # Use ReLU activation function after each FC layer          # \n",
    "        # (except the last one).The last layer output should be     #\n",
    "        # of `input_dim` size. Append all layers to `decoder_layers`#\n",
    "        #############################################################\n",
    "\n",
    "        ####################### End ##################################\n",
    "        self.decoder = nn.Sequential(*decoder_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_hat, z = None, None\n",
    "        dropped_out = self.dropout(x)\n",
    "        ################ P5 #######################\n",
    "        # Do the forward pass                     #\n",
    "        # use dropped_out instead of x            #\n",
    "        # Compute `x_hat` (reconstructed inputs), #\n",
    "        # and `z` (the latent variables)          #\n",
    "        ###########################################\n",
    "\n",
    "        ####################### End ###############\n",
    "        return x_hat, z, None \n",
    "\n",
    "    def get_loss(self, x, x_hat, *_):\n",
    "        ########### P6 ############\n",
    "        # Compute and return the  #\n",
    "        # MSE between x and x_hat #\n",
    "        ###########################  \n",
    "\n",
    "        ########### End ###########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4fVt7jt5IDy2"
   },
   "source": [
    "# train and test functions\n",
    "in the following cells we enumerate on datasets and on each batch, first we flatten 28*28 image to 784 and then giving this to forward pass of our model. then by computing loss and running backprop on loss we can have all the gradients. then by calling optimizer.step() we update all the parameters.\n",
    "in test function we find loss and report that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fZAgXvj49enS"
   },
   "outputs": [],
   "source": [
    "LOG_INTERVAL = 200\n",
    "def train(model, optimizer, verbose=True):\n",
    "    \"\"\"\n",
    "    This function trains a `model` on `train_loader` for 1 epoch and prints the\n",
    "    loss value\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (x, _) in enumerate(tqdm(train_loader, desc='Batches', leave=False)):\n",
    "        x = x.flatten(start_dim=1).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        x_hat, mu, logvar = model(x)\n",
    "        loss = model.get_loss(x, x_hat, mu, logvar)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if verbose and batch_idx % LOG_INTERVAL == LOG_INTERVAL-1:\n",
    "            print('    Train [%d/%d]\\t | \\tLoss: %.5f' % (batch_idx * x.shape[0], len(train_loader.dataset), loss.item() / x.shape[0]))\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    if verbose:\n",
    "        print('==> Train | Average loss: %.4f' % train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DNJDt3PI_Pgb"
   },
   "outputs": [],
   "source": [
    "def test(model, verbose=True):\n",
    "    \"\"\"\n",
    "    This function tests a `model` on a `test_loader` and prints the loss value\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, _ in test_loader:\n",
    "            x = x.flatten(start_dim=1).to(device)\n",
    "            x_hat, mu, logvar = model(x)\n",
    "            loss = model.get_loss(x, x_hat, mu, logvar)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    if verbose:\n",
    "        print('==> Test  | Average loss: %.4f' % test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P3ywueRb_T0W"
   },
   "outputs": [],
   "source": [
    "def run(model, n_epoch, verbose=True):\n",
    "    \"\"\"\n",
    "    This function will optimize parameters of `model` for `n_epoch` epochs\n",
    "    on `train_loader` and validate it on `test_loader`.\n",
    "    \"\"\"\n",
    "    LEARNING_RATE = 5e-5\n",
    "    ###################### P7 ################################\n",
    "    # Send `model` to the desired device, defined in `device`#\n",
    "    ##########################################################\n",
    "\n",
    "    ####################### End ##############################\n",
    "\n",
    "    optimizer = None\n",
    "    ################## P8 #####################\n",
    "    # Initialize a new Adam optimizer         #\n",
    "    ###########################################\n",
    "\n",
    "    ################## End ####################\n",
    "\n",
    "    for epoch in trange(1, n_epoch+1, desc='Epochs', leave=True):\n",
    "        if verbose:\n",
    "            print('\\nEpoch %d:' % epoch)\n",
    "        train(model, optimizer, verbose)\n",
    "        test(model, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BOT1eKuyAPwK"
   },
   "outputs": [],
   "source": [
    "#run this cell to train model and report loss on test dataset\n",
    "ae = AE(28*28, [512,128,64], 30, [64,128,512])\n",
    "run(ae,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cQ-IaIorHH5J"
   },
   "outputs": [],
   "source": [
    "def show(images, rows=1):\n",
    "    \"\"\"\n",
    "    This function gets multiple MNIST images and plots them in the given number\n",
    "    of rows.\n",
    "    \"\"\"\n",
    "    if images.shape[-1] == 784 or images.shape[1] == 1:\n",
    "        images = images.reshape(-1, 28, 28)\n",
    "    ########################### P9 #############################\n",
    "    # calculate the #cols that we need and then plot images in #\n",
    "    # appropriate #cols and #rows                              #\n",
    "    ############################################################\n",
    "\n",
    "    ############################ end ###########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XUN_B2P6X-nf"
   },
   "source": [
    "#VAE\n",
    "now similar to auto encoder we want to make class that inherit from AE class and implement VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ELcUC5JyGFLK"
   },
   "outputs": [],
   "source": [
    "class VAE(AE):\n",
    "    def __init__(self, input_dim, encoder_dims, z_dim, decoder_dims):\n",
    "        super(VAE, self).__init__(input_dim, encoder_dims, z_dim, decoder_dims)\n",
    "        \n",
    "        self.type_str = 'VAE'\n",
    "        del self.z_layer  # z_layer is not needed anymore\n",
    "\n",
    "        # Drouput, Encoder, and Decoder have been defined in AE class\n",
    "\n",
    "        # mu and sigma_matrix part\n",
    "        self.mu_layer, self.logvar_layer = None, None\n",
    "        ############################# P10 #############################\n",
    "        # Define mu and logvar layers                                 #\n",
    "        # Notice that we should have a logvar_layer, not a sigma_layer#\n",
    "        # Do not use any activation function                          #\n",
    "        ###############################################################\n",
    "\\\n",
    "        ############################## End ############################\n",
    "\n",
    "    @staticmethod\n",
    "    def reparameterize(mu, logvar):\n",
    "        z = None\n",
    "        ############################### P11 #################################\n",
    "        # Sample `z` from N(`mu`, e^`logvar`) in a way that the gradient can#\n",
    "        # backpropagate through this sampling operation                     #\n",
    "        #####################################################################\n",
    "\n",
    "        ############################### End ##################################\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_hat, mu, logvar = None, None, None\n",
    "        dropped_out = self.dropout(x)\n",
    "        ################################# P12 ####################################\n",
    "        # Do the forward pass                                                    #\n",
    "        # Compute `x_hat` (reconstructed inputs), `mu`, and `logvar` (outputs of #\n",
    "        # `mu_layer` and `logvar_layer` respectively)                            #\n",
    "        # Use reparameterization trick (the function you have implemented)       #\n",
    "        ##########################################################################\n",
    "\n",
    "        ################################### End ###################################\n",
    "        return x_hat, mu, logvar\n",
    "    \n",
    "    def get_loss(self, x, x_hat, mu, logvar):\n",
    "        MSE, KLD = 0, 0\n",
    "        ################################## P13 ######################################\n",
    "        # Compute the VAE loss (Assuming Guassian distribution for the decoder      #\n",
    "        # output)                                                                   #\n",
    "        #############################################################################\n",
    "\n",
    "        ################################## End ######################################\n",
    "        return MSE + KLD\n",
    "\n",
    "    def generate(self, n):\n",
    "        samples = None\n",
    "        ################################## P14 ##################################\n",
    "        # Generate `n` random noises from N(0, I), feed it into the decoder and #\n",
    "        # generate `n` samples                                                  #\n",
    "        #########################################################################\n",
    "\n",
    "        ################################### End #################################\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HTu9wXLaKje"
   },
   "source": [
    "#Training VAE\n",
    "using the functions from last part we can train our VAE model and see the loss on train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yvGR68wkVhLb"
   },
   "outputs": [],
   "source": [
    "vae = VAE(28*28, [512,128,64], 30, [64,128,512])\n",
    "run(vae,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0x9k7-BIX0Sj"
   },
   "outputs": [],
   "source": [
    "def plot_reconstructions(models, n):\n",
    "    x = next(iter(test_loader))[0][:n]  # Get a batch and choose `n` of images\n",
    "    print('Data')\n",
    "    show(x.squeeze(1))\n",
    "\n",
    "    x = x.flatten(start_dim=1).to(device)\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        x_hat, _, _ = model(x)\n",
    "        print('%s %dD' % (model.type_str, model.z_dim))\n",
    "        show(x_hat.detach().cpu())\n",
    "models = [ae,vae]\n",
    "plot_reconstructions(models, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PScr5kf_zJpL"
   },
   "source": [
    "#interpolation part1\n",
    "now we want to produce first image that has new features. there is probablity that these features even not exist in train dataset. in this part we want to find the mean of some trouser images in z space and then find mean of some shirt image in z space. then add this means together and give this new z to decoder. we expect that we have Tshirt that has trouser on it.\n",
    "this is so usefull. consider some images of some faces. mean all the faces that has smile on theire faces and similar thing to all faces that has no smile. then subtract no smile mean in z space from smile faces in z-space. this work gives you the smile in z space. so you can add this smile to every face and make angry face to happy face !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fl-hQpZu1Icv"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.FashionMNIST('./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.FashionMNIST('./data', train=False, transform=transforms.ToTensor())\n",
    "idx = test_dataset.targets == 0\n",
    "test_dataset.targets = test_dataset.targets[idx]\n",
    "test_dataset.data = test_dataset.data[idx]\n",
    "test_loader_trouser = torch.utils.data.DataLoader(test_dataset, **data_loader_kwargs)\n",
    "x = next(iter(test_loader_trouser))[0][:20]  # Get a batch and choose `n` of images\n",
    "print('Data')\n",
    "show(x.squeeze(1))\n",
    "\n",
    "train_dataset = datasets.FashionMNIST('./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.FashionMNIST('./data', train=False, transform=transforms.ToTensor())\n",
    "idx = test_dataset.targets == 1\n",
    "test_dataset.targets = test_dataset.targets[idx]\n",
    "test_dataset.data = test_dataset.data[idx]\n",
    "test_loader_shirts = torch.utils.data.DataLoader(test_dataset, **data_loader_kwargs)\n",
    "x = next(iter(test_loader_shirts))[0][:20]  # Get a batch and choose `n` of images\n",
    "print('Data')\n",
    "show(x.squeeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T_DeS2yhiY72"
   },
   "outputs": [],
   "source": [
    "def combine(model, n_rows):\n",
    "    \"\"\"\n",
    "    This function interpolates n_cols images between two random MNIST image\n",
    "    \"\"\"\n",
    "    plt.rcParams['figure.figsize'] = (5, 5)\n",
    "    x = next(iter(test_loader_trouser))[0][:2 * n_rows].flatten(start_dim=1).to(device)\n",
    "    y = next(iter(test_loader_shirts))[0][:2 * n_rows].flatten(start_dim=1).to(device)\n",
    "    shirt_with_trouser = None\n",
    "    ########################## P15 ###############################\n",
    "    # use x , y and find mean of trousers and Tshirts in z space #\n",
    "    # then add theme together in z space and store this value    #\n",
    "    # in shirt_with_trouser                                      #\n",
    "    ########################## end ###############################\n",
    "\n",
    "    ######################### end ##############################\n",
    "    img = model.decoder(shirt_with_trouser).cpu().detach()\n",
    "    img = img.reshape(-1, 28, 28)\n",
    "    plt.imshow(img[0],cmap = \"gray\")\n",
    "vae = vae.to(device)\n",
    "combine(vae, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A_qzgGIMUU3u"
   },
   "source": [
    "#interpolations part 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jxPmRPloBAOk"
   },
   "outputs": [],
   "source": [
    "def plot_interpolations(model, n_rows, n_cols=10):\n",
    "    \"\"\"\n",
    "    This function interpolates n_cols images between two random MNIST image\n",
    "    \"\"\"\n",
    "    plt.rcParams['figure.figsize'] = (n_cols, n_rows)\n",
    "    x = next(iter(test_loader))[0][:2 * n_rows].flatten(start_dim=1).to(device)\n",
    "    for i in range(n_rows):\n",
    "        img1 = x[2 * i]\n",
    "        img2 = x[2 * i + 1]\n",
    "        model.eval()\n",
    "        images = list()\n",
    "        ################################ P16 #####################################\n",
    "        # give your images(img1,img2) to model and get latent value for each     #\n",
    "        # images.call them z1 and z2. then in z dimension space split the line   #\n",
    "        # distance between z1 and z2,into n_cols and start to move from z1 to z2 #\n",
    "        # and find n_cols point between z1 and z2 (in z_dim space). then use     #\n",
    "        # decoder for new points in z_space and get new image for each point.    #\n",
    "        # first append img1 to images list then append all new image that        #\n",
    "        # decoders produced and then append img2 at the end of list.             #\n",
    "        ##########################################################################\n",
    "\n",
    "        ################################ end #####################################\n",
    "        images = torch.stack(images)\n",
    "        print('%s %dD' % (model.type_str, model.z_dim))\n",
    "        show(images)\n",
    "    print('---\\n')\n",
    "plot_interpolations(ae, 3)\n",
    "plot_interpolations(vae, 3)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ML_HW6_P1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
