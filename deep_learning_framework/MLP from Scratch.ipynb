{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MLP from Scratch.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNjVjr0EgZzHYyWrj2t9fCy"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"cgypDGY1Bgou","colab_type":"text"},"source":["# Building an MLP from scratch with Pytorch"]},{"cell_type":"code","metadata":{"id":"EHbuXJlYBg_n","colab_type":"code","colab":{}},"source":["import torch\n","from torch.autograd import Variable\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sljshWOvBseK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"187ebbf1-ab57-497a-9b88-0ce07c05131f","executionInfo":{"status":"ok","timestamp":1591084924222,"user_tz":-270,"elapsed":1589,"user":{"displayName":"Yasamin Tabatabaee","photoUrl":"","userId":"07445355406834081164"}}},"source":["# loading the data\n","from sklearn.datasets import load_iris\n","\n","data, label = load_iris(return_X_y = True)\n","ind = np.where(label < 2)\n","X = torch.tensor(data[ind]).float()\n","Y = torch.tensor(np.eye(2)[label[ind]]).float() # one-hotting the label\n","print(X.shape, Y.shape)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["torch.Size([100, 4]) torch.Size([100, 2])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5OpXIZeIC6ir","colab_type":"code","colab":{}},"source":["class MLP:\n","\n","  def __init__(self, input_size=4, hidden_size=3, num_classes=2, lr=1e-3):\n","    self.W1 = Variable(torch.randn(input_size, hidden_size), requires_grad=True)\n","    self.b1 = Variable(torch.randn(hidden_size), requires_grad=True)\n","    #self.W1.data.fill_(1.)\n","    #self.b1.data.fill_(1.)\n","\n","    self.W2 = Variable(torch.randn(hidden_size, num_classes), requires_grad=True)\n","    self.b2 = Variable(torch.randn(num_classes), requires_grad=True)\n","    #self.W2.data.fill_(1.)\n","    #self.b2.data.fill_(1.)\n","\n","    self.lr = lr\n","\n","  def relu(self, x):\n","    # torch max is elementwise, we can't pass a scalar 0 to it\n","    return torch.max(x, torch.zeros_like(x))\n","\n","  def softmax(self, x):\n","    e = torch.exp(x - torch.max(x)) # the - is for more stability\n","    return e / e.sum()\n","\n","  def cross_entropy(self, y, o):\n","    t = y * torch.log(o + 1e-10)\n","    return -torch.sum(t)\n","\n","  def forward(self, x):\n","    h = self.relu(torch.matmul(x, self.W1) + self.b1)\n","    o = self.softmax(torch.matmul(h, self.W2) + self.b2)\n","    return o\n","\n","  def backward(self, loss):\n","    loss.backward()\n","\n","    self.W1.data -= self.lr * self.W1.grad.data\n","    self.b1.data -= self.lr * self.b1.grad.data\n","\n","    self.W2.data -= self.lr * self.W2.grad.data\n","    self.b2.data -= self.lr * self.b2.grad.data\n","\n","  def train(self, x, y, epochs):\n","    for epoch in range(epochs):\n","      losses = []\n","      for sample, label in zip(x, y):\n","        o = self.forward(sample)\n","        loss = self.cross_entropy(label, o)\n","        self.backward(loss)\n","        losses += [loss.item()]\n","      \n","      loss = np.mean(losses)\n","      if (epoch+1) % 10 == 0:\n","        print('epoch', epoch+1, ', loss', loss)    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DRhrKMYAM9WC","colab_type":"code","colab":{}},"source":["mlp = MLP()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8nTSMVPBNKbX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":189},"outputId":"9aedf3e0-cd05-4f2a-a0de-87a7ee35fe5f","executionInfo":{"status":"ok","timestamp":1591087830397,"user_tz":-270,"elapsed":6232,"user":{"displayName":"Yasamin Tabatabaee","photoUrl":"","userId":"07445355406834081164"}}},"source":["mlp.train(X, Y, epochs=100)"],"execution_count":42,"outputs":[{"output_type":"stream","text":["epoch 10 , loss 0.982461998462677\n","epoch 20 , loss 0.6689040878415108\n","epoch 30 , loss 0.9823818069696426\n","epoch 40 , loss 0.6696574705839157\n","epoch 50 , loss 0.9817364364862442\n","epoch 60 , loss 0.6715824556350708\n","epoch 70 , loss 0.9805195915699005\n","epoch 80 , loss 0.6746719020605088\n","epoch 90 , loss 0.9787228834629059\n","epoch 100 , loss 0.6789108946919441\n"],"name":"stdout"}]}]}