{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML for Bioinformatics\n",
    "## HW6 - Long short-term memory\n",
    "\n",
    "---\n",
    "\n",
    "Name: \n",
    "\n",
    "Student No.:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b7AEKlrozS6J"
   },
   "source": [
    "# ECG Heartbeat Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QcS0LXgezkNM"
   },
   "source": [
    "In this exercise you will implement an LSTM neural network that can classify ambulatory ECG recordings into 5 different classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2pAEksut0ds-"
   },
   "source": [
    "# Collect Data\n",
    "We use a preprocessed version of a famous datasets in heartbeat classification, [the MIT-BIH Arrhythmia Dataset](https://physionet.org/content/mitdb/1.0.0/). \n",
    "The signals in this dataset correspond to electrocardiogram (ECG) shapes of heartbeats for the normal case and the cases affected by different arrhythmias and myocardial infarction. We will use the Arrhythmia Dataset used in [this paper](https://arxiv.org/abs/1805.00794) which is the preprocessed arrhythmia dataset consisting of signals that are preprocessed and segmented, with each segment corresponding to a heartbeat in the dataset. This dataset is composed of 109446 samples which are classified into 5 categories. You must download the dataset from [here](https://drive.google.com/file/d/1a8IetOZkvnq8D8K6k8EdMsFGeqE2Hv5M/view?usp=sharing). It is also accessible on [kaggle](https://www.kaggle.com/shayanfazeli/heartbeat)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x28te2lu3vtG"
   },
   "source": [
    "The training and test data is located in mitbih_train.csv and mitbih_test.csv files. Locate these files in dataset folder next to this notebook. If you are running this notebook on colab, the following code does this phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KbLhdqNkGjsD"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "FOLDERNAME = 'MLB_RNN_Assignment/dataset'\n",
    "\n",
    "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
    "\n",
    "%cd drive/My\\ Drive\n",
    "%cp -r $FOLDERNAME ../../\n",
    "%cd ../../\n",
    "%cd dataset\n",
    "!unzip 29414_37484_bundle_archive.zip\n",
    "!rm 29414_37484_bundle_archive.zip\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5rNDU40outel"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6cYl6SFb5LK_"
   },
   "source": [
    "# Create Custom Dataset\n",
    "You need to create your custom dataset so you can define a dataloader to use in the train and test phase. Your class must implement init, getitem and len methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q74ZiMGXv_iU"
   },
   "outputs": [],
   "source": [
    "class HeartbeatDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, csv_file):\n",
    "        #TODO\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #TODO\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        #TODO\n",
    "        pass\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_set = HeartbeatDataset('dataset/mitbih_train.csv')\n",
    "train_loader = DataLoader(dataset=train_set,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)                          \n",
    "\n",
    "test_set = HeartbeatDataset('dataset/mitbih_test.csv')\n",
    "test_loader = DataLoader(dataset=test_set,\n",
    "                        batch_size=batch_size,\n",
    "                         shuffle=True)                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k84-xDUs6j02"
   },
   "source": [
    "# Create LSTM Classifier\n",
    "Now you are ready to implement your LSTM neural network which inherits from nn.Module. The structure of the network must be as follows:\n",
    "\n",
    "  (lstm): LSTM(1, hidden_dim) <br>\n",
    "  (fully_connected): Linear(in_features=hidden_dim, out_features=middle_dim, bias=True) <br>\n",
    "  (fully_connected): Linear(in_features=middle_dim, out_features=5, bias=True) <br>\n",
    "  (softmax): Softmax(dim=1)\n",
    ")\n",
    "\n",
    "At each step the value of signal is given as input to the LSTM block. The hidden state and cell state get updated and the final output is computed by two fully connected after the final hidden state with a softmax layer at the end.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MYCYQzmoBFmy"
   },
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, fc_dim, target_dim):\n",
    "        #TODO\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        #TODO\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i7mM-W9l835A"
   },
   "source": [
    "# Define loss function and optimizer\n",
    "Next you can instance a classifier, loss function and optimizer. You are free to change the loss function, the optimizer and their parameters along with dimensions of the hidden state and the fully connected layer of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VgiXWDO5U3XV"
   },
   "outputs": [],
   "source": [
    "lstm_classifier = LSTMClassifier(1, 64, 32, 5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_classifier.parameters(), lr=0.01, momentum=0.9)\n",
    "print(lstm_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5VfHNXhf9QQj"
   },
   "source": [
    "# Train the classifier\n",
    "The following code runs the training phase using what you have build so far. You can edit the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bgquaPZQRtCw"
   },
   "outputs": [],
   "source": [
    "epoch_num = 5\n",
    "print_every = 100\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    running_loss = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data                  \n",
    "        optimizer.zero_grad()\n",
    "        outputs = lstm_classifier(inputs)        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if (i+1)%print_every == 0:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / print_every))\n",
    "            running_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SCdYMdlf9yhv"
   },
   "source": [
    "# Test the classifier\n",
    "The following code runs the LSTM classifier on test data and reports the results for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VYymO6cwR3tS"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "class_correct = [0 for i in range(5)]\n",
    "class_total = [0 for i in range(5)]\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data        \n",
    "        outputs = lstm_classifier(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        c = (predicted  == labels).squeeze()        \n",
    "        for i in range(labels.size(0)):\n",
    "            label = labels[i]\n",
    "            correct += c[i].item()\n",
    "            total += 1\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(5):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "    print(class_correct[i], class_total[i])\n",
    "\n",
    "\n",
    "print('%d / %d' % (correct, total))\n",
    "print('Accuracy: %0.2f' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6JFMXaL4-lRE"
   },
   "source": [
    "# Useful Links and Acknowledgements\n",
    "\n",
    "[An Effective LSTM Recurrent Network to Detect Arrhythmia on Imbalanced ECG Dataset](https://www.hindawi.com/journals/jhe/2019/6320651/)\n",
    "\n",
    "[Classify ECG Signals Using Long Short-Term Memory Networks\n",
    "](https://https://www.mathworks.com/help/signal/examples/classify-ecg-signals-using-long-short-term-memory-networks.html)\n",
    "\n",
    "[Sequence Models and Long-Short Term Memory Networks](https://https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html)\n",
    "\n",
    "[LSTMs for Time Series in PyTorch](https://www.jessicayung.com/lstms-for-time-series-in-pytorch/)\n",
    "\n",
    "[ECG Heartbeat Classification: A Deep Transferable Representation\n",
    "](https://https://arxiv.org/abs/1805.00794)\n",
    "\n",
    "[MIT-BIH Arrhythmia Database](https://https://physionet.org/content/mitdb/1.0.0/)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNCnek+T9ZTOrDf52oYhK3X",
   "collapsed_sections": [],
   "name": "LSTM_heartbeat_classification.ipynb",
   "provenance": [
    {
     "file_id": "1GG1ZPdd-SNUxlve_jJlTPvaS2ZRcxMwW",
     "timestamp": 1592841880914
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
